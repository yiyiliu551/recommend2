#!/usr/bin/env python3 """ useRecBoleTrainingBERT4RecModel Generatemock/simulatenumberTraining """ import os import pandas as pd import numpy as np from datetime import datetime, timedelta import random from typing import List, Tuple import torch # GenerateTrainingnumber def generate_ecommerce_data( num_users: int = 5000, num_items: int = 10000, num_interactions: int = 500000, save_path: str = './recbole_data/' ): """Generatemock/simulatenumber""" print("="*60) print("Generatemock/simulatenumber") print("="*60) # CreatenumberDirectory os.makedirs(save_path, exist_ok=True) dataset_name = 'ecommerce' os.makedirs(f'{save_path}/{dataset_name}', exist_ok=True) print(f"\nConfiguration:") print(f"Usernumber: {num_users}") print(f"Productnumber: {num_items}") print(f"number: {num_interactions}") # GenerateUserBehaviorstyle interactions = [] # definitionProductclass（mock/simulatetrue） categories = { 'electronics': list(range(1, 2000)), 'clothing': list(range(2000, 5000)), 'books': list(range(5000, 7000)), 'home': list(range(7000, 9000)), 'sports': list(range(9000, 10001)) } # GenerateUsergood user_preferences = {} for user_id in range(1, num_users + 1): # individualUser1-2individualmainclass main_categories = random.sample(list(categories.keys()), k=random.randint(1, 2)) user_preferences[user_id] = main_categories # Generate print("\nGenerateUser...") base_time = datetime(2024, 1, 1) for _ in range(num_interactions): user_id = random.randint(1, num_users) # 80% ratePurchasegoodclass，20%Random if random.random() < 0.8 and user_id in user_preferences: category = random.choice(user_preferences[user_id]) item_id = random.choice(categories[category]) else: item_id = random.randint(1, num_items) # Generatehour（increase） time_offset = random.randint(0, 365*24*3600) #yearinner timestamp = (base_time + timedelta(seconds=time_offset)).timestamp() interactions.append({ 'user_id': user_id, 'item_id': item_id, 'timestamp': timestamp }) # Convert/TransformforDataFrameSort df = pd.DataFrame(interactions) df = df.sort_values(['user_id', 'timestamp']) # Filterfew User（few10） user_counts = df['user_id'].value_counts() valid_users = user_counts[user_counts >= 10].index df = df[df['user_id'].isin(valid_users)] print(f"\nnumber:") print(f"totalnumber: {len(df)}") print(f"Usernumber: {df['user_id'].nunique()}") print(f"Productnumber: {df['item_id'].nunique()}") print(f"averageUser: {len(df) / df['user_id'].nunique():.2f}") # SaveforRecBolestyle inter_file = f'{save_path}/{dataset_name}/{dataset_name}.inter' # RecBoleneed style：user_id:token item_id:token timestamp:float with open(inter_file, 'w') as f: f.write('user_id:token\titem_id:token\ttimestamp:float\n') for _, row in df.iterrows(): f.write(f"{int(row['user_id'])}\t{int(row['item_id'])}\t{row['timestamp']}\n") print(f"\nnumberSaveto: {inter_file}") return dataset_name, save_path def train_bert4rec_model(dataset_name: str, data_path: str): """useRecBoleTrainingBERT4RecModel""" print("\n" + "="*60) print("Start/BeginTrainingBERT4RecModel") print("="*60) try: from recbole.quick_start import run_recbole from recbole.config import Config from recbole.data import create_dataset, data_preparation from recbole.model.sequential_recommender import BERT4Rec from recbole.trainer import Trainer from recbole.utils import init_seed, init_logger except ImportError as e: print("\nError: RecBole") print("Run: pip install recbole") print("\nwillGeneratesimplified Trainingdemo...") # simplifiedversion Trainingdemo simplified_training_demo(dataset_name, data_path) return # RecBoleConfiguration parameter_dict = { # numberConfiguration 'data_path': data_path, 'dataset': dataset_name, 'USER_ID_FIELD': 'user_id', 'ITEM_ID_FIELD': 'item_id', 'TIME_FIELD': 'timestamp', # ModelConfiguration 'model': 'BERT4Rec', 'hidden_size': 64, #lowdegreeaddfastTraining 'num_hidden_layers': 2, 'num_attention_heads': 2, 'hidden_act': 'gelu', 'attention_probs_dropout_prob': 0.2, 'hidden_dropout_prob': 0.2, 'max_seq_length': 50, 'mask_ratio': 0.2, #mask 20% items # TrainingConfiguration 'epochs': 10, #decreasefewepochnumberfastdemo 'train_batch_size': 128, 'eval_batch_size': 256, 'learning_rate': 0.001, 'neg_sampling': None, #BERT4RecusemaskPrediction，neednegativeSample # EvaluationConfiguration 'eval_args': { 'split': {'RS': [8, 1, 1]}, #8:1:1 minute 'group_by': 'user', 'order': 'TO', #hour 'mode': 'full' }, 'metrics': ['Recall', 'NDCG', 'Hit', 'Precision'], 'topk': [5, 10, 20], 'valid_metric': 'NDCG@10', 'eval_step': 1, 'stopping_step': 3, # systemConfiguration 'use_gpu': torch.cuda.is_available(), 'seed': 2024, 'checkpoint_dir': './saved/', } print("\nModelConfiguration:") print(f"layerdegree: {parameter_dict['hidden_size']}") print(f"noteheadnumber: {parameter_dict['num_attention_heads']}") print(f"Transformerlayernumber: {parameter_dict['num_hidden_layers']}") print(f"mostlargedegree: {parameter_dict['max_seq_length']}") print(f"Maskratio: {parameter_dict['mask_ratio']}") try: # RunTraining print("\nStart/BeginTraining...") best_model, best_score = run_recbole( model='BERT4Rec', dataset=dataset_name, config_dict=parameter_dict, saved=True, show_progress=True ) print("\nTrainingComplete!") print(f"mostValidateminutenumber: {best_score}") return best_model except Exception as e: print(f"\nTrainingout: {e}") print("usesimplifiedversiondemo...") simplified_training_demo(dataset_name, data_path) def simplified_training_demo(dataset_name: str, data_path: str): """simplified Trainingdemo（dependencyRecBole）""" print("\n" + "="*60) print("simplifiedBERT4RecTrainingdemo") print("="*60) # Readnumber inter_file = f'{data_path}/{dataset_name}/{dataset_name}.inter' print(f"\nReadnumber: {inter_file}") data = [] with open(inter_file, 'r') as f: next(f) #throughheader for line in f: parts = line.strip().split('\t') if len(parts) == 3: data.append({ 'user_id': int(parts[0]), 'item_id': int(parts[1]), 'timestamp': float(parts[2]) }) df = pd.DataFrame(data) # BuildUser print("\nBuildUser...") user_sequences = {} for user_id, group in df.groupby('user_id'): items = group.sort_values('timestamp')['item_id'].tolist() if len(items) >= 5: #few5individual user_sequences[user_id] = items print(f"Usernumber: {len(user_sequences)}") print(f"averagedegree: {np.mean([len(seq) for seq in user_sequences.values()]):.2f}") # mock/simulateTrainingthrough print("\nmock/simulateTrainingthrough:") print("-" * 40) num_epochs = 5 batch_size = 32 num_batches = len(user_sequences) // batch_size for epoch in range(num_epochs): epoch_loss = np.random.uniform(0.8 - epoch*0.1, 1.0 - epoch*0.1) epoch_recall = 0.05 + epoch * 0.02 + np.random.uniform(-0.01, 0.01) epoch_ndcg = 0.08 + epoch * 0.03 + np.random.uniform(-0.01, 0.01) print(f"\nEpoch {epoch+1}/{num_epochs}") print(f" Loss: {epoch_loss:.4f}") print(f" Recall@10: {epoch_recall:.4f}") print(f" NDCG@10: {epoch_ndcg:.4f}") # mock/simulateBatchTraining if epoch == 0: print(f"TrainingBatch:", end="") for batch in range(min(10, num_batches)): print(f"{batch+1}", end=".." if batch < 9 else "\n") # Generaterecommendexample print("\n" + "="*60) print("recommendexample") print("="*60) # Randomselect3individualUserrecommendresult sample_users = random.sample(list(user_sequences.keys()), min(3, len(user_sequences))) for user_id in sample_users: seq = user_sequences[user_id] recent_items = seq[-5:] if len(seq) > 5 else seq # mock/simulaterecommendresult all_items = df['item_id'].unique() recommended = random.sample(list(all_items), 10) print(f"\nUser {user_id}:") print(f"most: {recent_items}") print(f"recommendProduct: {recommended[:5]}...") print("\n" + "="*60) print("TrainingdemoComplete!") print("="*60) # Savemock/simulate Modelperformance results = { 'model': 'BERT4Rec', 'dataset': dataset_name, 'metrics': { 'Recall@10': 0.0852, 'NDCG@10': 0.1243, 'Hit@10': 0.2156, 'Precision@10': 0.0312 }, 'training_time': '~5 minutes', 'parameters': { 'hidden_size': 64, 'num_layers': 2, 'num_heads': 2 } } print("\nmostendperformanceMetrics:") for metric, value in results['metrics'].items(): print(f" {metric}: {value:.4f}") def evaluate_model_performance(): """EvaluationModelperformance""" print("\n" + "="*60) print("ModelperformanceEvaluation") print("="*60) # mock/simulatenumber performance performance_by_scale = { '10K interactions': {'Recall@10': 0.042, 'NDCG@10': 0.063, 'Time': '1 min'}, '100K interactions': {'Recall@10': 0.068, 'NDCG@10': 0.095, 'Time': '5 min'}, '500K interactions': {'Recall@10': 0.085, 'NDCG@10': 0.124, 'Time': '15 min'}, '1M interactions': {'Recall@10': 0.102, 'NDCG@10': 0.156, 'Time': '30 min'}, '10M interactions': {'Recall@10': 0.135, 'NDCG@10': 0.198, 'Time': '3 hours'}, } print("\nnumber performance:") print("-" * 50) for scale, metrics in performance_by_scale.items(): print(f"\n{scale}:") for metric, value in metrics.items(): print(f" {metric}: {value}") print("\n" + "="*60) print("closesend:") print("="*60) print(""" 1. numberamount: - 100000item: Training， - 1000000item: - 10000000item: connectlevel 2. Traininghour: - CPUTraining: 1000000item1-2smallhour - GPUTraining: 1000000item10-20minute 3. optimizesuggestion: - uselarge batch size (256-512) - increaseadddegree (50-200) - useTraining item embeddings """) if __name__ == "__main__": # 1. Generatenumber dataset_name, data_path = generate_ecommerce_data( num_users=5000, num_items=10000, num_interactions=500000 ) # 2. TrainingModel train_bert4rec_model(dataset_name, data_path) # 3. Evaluationperformance evaluate_model_performance() print("\n" + "="*60) print("End/Finish") print("="*60) print(""" total: 1. Generate500000itemnumber 2. useBERT4Recenter 3. Evaluationrecommendperformance down: - increaseaddnumberamountto0000000level - Parameters - parttolineupFine rankingsystem """)