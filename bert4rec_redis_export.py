#!/usr/bin/env python3 """ BERT4RecOfflineCompute/CalculateresultExporttoRedis implementation """ import json import time import random from typing import List, Dict, Tuple from datetime import datetime import hashlib class RedisDataExporter: """RedisnumberExport（mock/simulate）""" def __init__(self): # mock/simulateRedisconnect self.redis_data = {} self.ttl = 3600 * 24 #24smallhourthrough def zadd(self, key: str, mapping: Dict[str, float]): """mock/simulateRedis ZADD""" self.redis_data[key] = mapping def hset(self, key: str, mapping: Dict): """mock/simulateRedis HSET""" self.redis_data[key] = mapping def setex(self, key: str, ttl: int, value: str): """mock/simulateRedis SETEX""" self.redis_data[key] = {'value': value, 'ttl': ttl} def pipeline_execute(self, commands: List[Tuple]): """mock/simulatePipelinebatchamountExecute""" for cmd in commands: if cmd[0] == 'zadd': self.zadd(cmd[1], cmd[2]) elif cmd[0] == 'hset': self.hset(cmd[1], cmd[2]) class BERT4RecOfflineProcessor: """BERT4RecOfflineProcess""" def __init__(self): self.redis_exporter = RedisDataExporter() self.batch_size = 1000 self.ttl = 3600 * 24 #24smallhourthrough def generate_recommendations(self, user_id: int, num_items: int = 200) -> List[Dict]: """Generaterecommendresult（mock/simulateBERT4RecOutput）""" recommendations = [] # mock/simulateBERT4Rec Output for position in range(1, num_items + 1): item_id = random.randint(1, 100000) score = 1.0 - (position - 1) * 0.001 + random.uniform(-0.01, 0.01) rec = { 'uid': user_id, 'item_id': item_id, 'position': position, 'score': round(score, 6), 'timestamp': int(time.time()), 'model_version': 'bert4rec_v2.1', 'features': { 'category': random.choice(['', '', '', '', 'dynamic']), 'price_range': random.choice(['low', 'medium', 'high']), 'user_segment': random.choice(['new', 'active', 'vip']) } } recommendations.append(rec) return recommendations def export_to_redis_sorted_set(self, recommendations: List[Dict], user_id: int): """ ExporttoRedis Sorted Set most style """ key = f"rec:v2:user:{user_id}" # Buildsorted setnumber zadd_data = {} metadata = {} for rec in recommendations: # memberstyle: itemid:position member = f"{rec['item_id']}:{rec['position']}" zadd_data[member] = rec['score'] # Storageunitnumber meta_key = f"rec:v2:meta:{user_id}:{rec['item_id']}" metadata[meta_key] = json.dumps({ 'pos': rec['position'], 'score': rec['score'], 'ts': rec['timestamp'], 'cat': rec['features']['category'], 'price': rec['features']['price_range'] }) # batchamountWriteRedis self.redis_exporter.zadd(key, zadd_data) for meta_key, meta_value in metadata.items(): self.redis_exporter.setex(meta_key, self.ttl, meta_value) return key def export_batch_format(self, user_ids: List[int]) -> Dict: """ batchamountExportstyle combinelargeOfflineProcess """ export_stats = { 'total_users': len(user_ids), 'total_items': 0, 'export_time': datetime.now().isoformat(), 'format': 'sorted_set', 'keys': [] } print(f"Start/BeginbatchamountExport {len(user_ids)} individualUser recommendresult...") for i, user_id in enumerate(user_ids): # Generaterecommend recommendations = self.generate_recommendations(user_id, num_items=200) # ExporttoRedis key = self.export_to_redis_sorted_set(recommendations, user_id) export_stats['keys'].append(key) export_stats['total_items'] += len(recommendations) if (i + 1) % 100 == 0: print(f"Process {i + 1}/{len(user_ids)} User") return export_stats def export_columnar_format(self, recommendations: List[Dict]) -> Dict: """ styleStoragestyle combineminuteandbatchamountProcess """ columnar_data = { 'uids': [], 'item_ids': [], 'positions': [], 'scores': [], 'timestamps': [], 'categories': [] } for rec in recommendations: columnar_data['uids'].append(rec['uid']) columnar_data['item_ids'].append(rec['item_id']) columnar_data['positions'].append(rec['position']) columnar_data['scores'].append(rec['score']) columnar_data['timestamps'].append(rec['timestamp']) columnar_data['categories'].append(rec['features']['category']) return columnar_data def export_protobuf_format(self, recommendations: List[Dict]) -> bytes: """ Protobufstyle（mock/simulate） combinehighperformancetransfer """ # mock/simulateprotobufserialize proto_data = { 'version': 1, 'recommendations': [] } for rec in recommendations: proto_rec = { 'u': rec['uid'], 'i': rec['item_id'], 'p': rec['position'], 's': int(rec['score'] * 1000000), #IntegerStorage 't': rec['timestamp'] } proto_data['recommendations'].append(proto_rec) # mock/simulateserialize serialized = json.dumps(proto_data).encode('utf-8') compressed = hashlib.md5(serialized).hexdigest()[:8] #mock/simulatecompress return f"PROTO:{compressed}".encode() class RedisQueryService: """Redisqueryservice""" def __init__(self, redis_exporter: RedisDataExporter): self.redis = redis_exporter def get_recommendations(self, user_id: int, offset: int = 0, limit: int = 20) -> List[Dict]: """ GetUserrecommendresult mock/simulate ZREVRANGE """ key = f"rec:v2:user:{user_id}" if key not in self.redis.redis_data: return [] # Getsorted setnumber items = self.redis.redis_data[key] # minutenumberSort sorted_items = sorted(items.items(), key=lambda x: x[1], reverse=True) # minutereturn results = [] for member, score in sorted_items[offset:offset + limit]: item_id, position = member.split(':') results.append({ 'item_id': int(item_id), 'position': int(position), 'score': score }) return results def get_user_stats(self, user_id: int) -> Dict: """GetUserrecommend""" key = f"rec:v2:user:{user_id}" if key not in self.redis.redis_data: return {'exists': False} items = self.redis.redis_data[key] scores = list(items.values()) return { 'exists': True, 'total_items': len(items), 'max_score': max(scores) if scores else 0, 'min_score': min(scores) if scores else 0, 'avg_score': sum(scores) / len(scores) if scores else 0 } def demonstrate_redis_export(): """demoRedisExport""" print("="*60) print("BERT4Rec OfflineCompute/CalculateresultExporttoRedis") print("="*60) processor = BERT4RecOfflineProcessor() # 1. UserExportexample print("\n1. UserExportexample") print("-"*40) user_id = 12345 recommendations = processor.generate_recommendations(user_id, num_items=100) print(f"User {user_id} recommendresultstyle:") sample_rec = recommendations[0] print(json.dumps(sample_rec, indent=2, ensure_ascii=False)) # ExporttoRedis redis_key = processor.export_to_redis_sorted_set(recommendations, user_id) print(f"\nExporttoRedis Key: {redis_key}") # 2. batchamountExport print("\n2. batchamountUserExport") print("-"*40) user_ids = list(range(10000, 10100)) #100individualUser stats = processor.export_batch_format(user_ids) print(f"\nExport:") print(f"totalUsernumber: {stats['total_users']}") print(f"totalrecommendnumber: {stats['total_items']}") print(f"averageUser: {stats['total_items'] / stats['total_users']:.0f} individualrecommend") # 3. querydemo print("\n3. Redisquerydemo") print("-"*40) query_service = RedisQueryService(processor.redis_exporter) # queryrecommendresult test_user = 10050 results = query_service.get_recommendations(test_user, offset=0, limit=10) print(f"\nUser {test_user} Top-10 recommend:") for i, item in enumerate(results, 1): print(f" {i}. ItemID: {item['item_id']}, " f"Score: {item['score']:.4f}, " f"Position: {item['position']}") # GetInformation stats = query_service.get_user_stats(test_user) print(f"\nUser {test_user} recommend:") print(f"totalrecommendnumber: {stats['total_items']}") print(f"mosthighminute: {stats['max_score']:.4f}") print(f"mostlowminute: {stats['min_score']:.4f}") print(f"averageminute: {stats['avg_score']:.4f}") def show_data_formats(): """ numberstyle""" print("\n" + "="*60) print("numberstyleforratio") print("="*60) processor = BERT4RecOfflineProcessor() recommendations = processor.generate_recommendations(99999, num_items=5) # 1. Sorted Setstyle print("\n1. Redis Sorted Setstyle (most)") print("-"*40) print("ZADD rec:user:99999") for rec in recommendations: print(f" {rec['score']:.6f} \"{rec['item_id']}:{rec['position']}\"") # 2. styleStoragestyle print("\n2. styleStoragestyle (combineminute)") print("-"*40) columnar = processor.export_columnar_format(recommendations) print(f"uids: {columnar['uids']}") print(f"item_ids: {columnar['item_ids']}") print(f"positions: {columnar['positions']}") print(f"scores: {[f'{s:.4f}' for s in columnar['scores']]}") # 3. JSONstyle print("\n3. JSONstyle (emptylarge)") print("-"*40) json_format = { 'uid': 99999, 'recommendations': [ {'item_id': r['item_id'], 'pos': r['position'], 'score': r['score']} for r in recommendations[:3] ] } print(json.dumps(json_format, indent=2)) # 4. compressstyle print("\n4. compressstyle (Storage)") print("-"*40) # Storageitem_idList，，minutenumberselect compressed = { 'u': 99999, 'items': [r['item_id'] for r in recommendations], 'v': 'v2.1', #version 't': int(time.time()) #hour } print(f"compressback: {json.dumps(compressed)}") print(f"beginlargesmall: ~{len(json.dumps(recommendations))} bytes") print(f"compressbacklargesmall: ~{len(json.dumps(compressed))} bytes") def show_best_practices(): """most""" print("\n" + "="*60) print("most") print("="*60) print(""" 1. numberstyleselect: ✅ Sorted Set: minute、Real-timeFilter、dynamic ✅ minutenumberdegree: 4-6smallnumber ✅ Memberformat: "itemid:metadata" 2. Storageoptimize: ✅ SetTTL: 24-48smallhourdynamicthrough ✅ compressStorage: segment ✅ minutepieceStorage: largeUserSplitmultipleindividualkey 3. Updatestrategy: ✅ allamountUpdate: daylow ✅ increaseamountUpdate: UsersmallhourUpdate ✅ Real-timeUpdate: VIPUserReal-timeCompute/Calculate 4. queryoptimize: ✅ Pipelinebatchamountquery ✅ Cachepointnumber ✅ levelstrategy: RedishourreturnPopular/Hotrecommend 5. monitoringMetrics: ✅ Redisrate > 99% ✅ querylatency < 5ms ✅ Storageempty: User < 10KB """) if __name__ == "__main__": # 1. demoExport demonstrate_redis_export() # 2. numberstyle show_data_formats() # 3. most show_best_practices() print("\n" + "="*60) print("total") print("="*60) print(""" BERT4RecOfflineCompute/Calculate + RedisCache: 1. OfflineBatch processingCompute/CalculateUser recommendresult 2. style: UID -> [(ItemID, Position, Score), ...] 3. inRedis Sorted Set，highquery 4. OnlineserviceconnectRead，latency < 5ms is ，recommendamount，fullperformance。 """)